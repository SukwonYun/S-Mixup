# S-Mixup: Structural Mixup for Graph Neural Networks

<p align="center">   
    <a href="https://pytorch.org/" alt="PyTorch">
      <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?e&logo=PyTorch&logoColor=white" /></a>
    <a href="https://uobevents.eventsair.com/cikm2023//" alt="Conference">
        <img src="https://img.shields.io/badge/CIKM'23-green" /></a>
</p>

The official source code for **"S-Mixup: Structural Mixup for Graph Neural Networks"**, accepted at CIKM 2023 (Short Paper).

## Overview
Applying the mixup technique in the graph domain is challenging due to the inherent structural information in graphs. While recent studies have attempted to address such scenarios, they mostly concentrate on graph classification tasks. The research in node classification, on the other hand, is still under-explored. In this paper, we propose a novel mixup augmentation for node classification called Structural Mixup (S-Mixup). The core idea is to take into account the structural information while mixing nodes. Specifically, S-Mixup obtains pseudo-labels for unlabeled nodes in a graph along with their prediction confidence via a Graph Neural Network (GNN) classifier. These serve as the criteria for the composition of the mixup pool for both inter and intra-class mixups. Furthermore, we utilize the edge gradient, obtained from the GNN training, and propose an edge gradient-based edge selection strategy for selecting edges to be attached to the nodes generated by mixup. Through extensive experiments on real-world benchmark datasets, we demonstrate the effectiveness of S-Mixup evaluated on the node classification task. We observe that S-Mixup enhances the robustness and generalization performance of GNNs, especially in heterophilous situations, making it a valuable tool for graph-based learning tasks.
  

<img src="https://github.com/FFTYYY/TWIRLS/assets/68312164/f6672775-4890-45f5-9c36-a321544bfef9" style="display: block; margin: 0 auto; width:750px; height:420px;">
  

### Requirements
- python version: 3.7.11
- numpy version: 1.19.2
- pytorch version: 1.8.0
- torch-geometric version: 2.0.1

### How to run
Following Options can be passed to `main.py`

`--dataset:` Name of the dataset. cora, citeseer, pubmed, cs, physics are available.  
usage example: `--dataset cora`

`--target_ratio:`
Determine upper and lower $r$%  for high and low-confidence node mixup pool.  
usage example: `--target_ratio 0.3`

`--edge_ratio:` Determine top $m$% of edge gradeint values.  
usage example: `--edge_ratio 0.1`

`--eta:` Controls loss between inter-class and intra-class node mixup.  
usage example: `--eta 0.5`

`--mixup_start:` Determine when mixup starts.  
usage example: `--mixup_start 30`

### How to Run

```
python main.py --dataset cora --target_ratio 0.3 --edge_ratio 0.1 --eta 0.5 --mixup_start 30
```

